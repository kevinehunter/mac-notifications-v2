"""Example module showing comprehensive documentation standards.

This module demonstrates the documentation standards for the Mac Notifications
project. It includes examples of module, class, and function documentation
with proper type hints and inline comments.

Architecture Notes:
    This is a demonstration module showing best practices for documentation.
    Real modules should follow these patterns but with actual implementation.

Usage:
    from examples.documentation_example import WellDocumentedClass
    
    instance = WellDocumentedClass("example")
    result = instance.process_data({"key": "value"})

See Also:
    - Google Python Style Guide: https://google.github.io/styleguide/pyguide.html
    - PEP 484 - Type Hints: https://www.python.org/dev/peps/pep-0484/
"""

from typing import Dict, List, Optional, Union, Tuple, Any, Callable
from datetime import datetime
from pathlib import Path
import logging

# Type aliases for clarity
NotificationData = Dict[str, Any]
ProcessingResult = Tuple[bool, Optional[str], Dict[str, Any]]
CallbackFunction = Callable[[NotificationData], None]

# Module-level constants with documentation
DEFAULT_TIMEOUT: int = 30  # Seconds to wait for processing
MAX_RETRIES: int = 3      # Maximum number of retry attempts
BATCH_SIZE: int = 100     # Number of items to process in one batch

# Configure module logger
logger = logging.getLogger(__name__)


class WellDocumentedClass:
    """Example class demonstrating comprehensive documentation.
    
    This class shows how to properly document a Python class including
    attributes, methods, properties, and special considerations. It follows
    Google-style docstrings and includes type hints throughout.
    
    Attributes:
        name (str): Identifier for this instance
        config (Dict[str, Any]): Configuration dictionary
        _private_attr (int): Private attribute (not documented in public API)
        
    Properties:
        is_active: Whether the instance is currently active
        processed_count: Number of items processed
        
    Class Attributes:
        DEFAULT_CONFIG (Dict[str, Any]): Default configuration values
        SUPPORTED_TYPES (List[str]): List of supported data types
        
    Thread Safety:
        This class is NOT thread-safe. Use threading.Lock if accessing
        from multiple threads.
        
    Example:
        Basic usage:
        >>> instance = WellDocumentedClass("my_processor")
        >>> instance.start()
        >>> result = instance.process_data({"type": "notification"})
        >>> instance.stop()
        
        With configuration:
        >>> config = {"timeout": 60, "retries": 5}
        >>> instance = WellDocumentedClass("processor", config=config)
        
    Note:
        This class requires Python 3.8+ due to use of assignment expressions.
        For older Python versions, use WellDocumentedClassLegacy.
    """
    
    # Class-level attributes
    DEFAULT_CONFIG: Dict[str, Any] = {
        "timeout": DEFAULT_TIMEOUT,
        "retries": MAX_RETRIES,
        "verbose": False
    }
    
    SUPPORTED_TYPES: List[str] = ["notification", "event", "alert"]
    
    def __init__(
        self,
        name: str,
        config: Optional[Dict[str, Any]] = None,
        callback: Optional[CallbackFunction] = None
    ) -> None:
        """Initialize WellDocumentedClass instance.
        
        Creates a new instance with the specified configuration. If no
        config is provided, uses DEFAULT_CONFIG. The callback function
        will be called after each successful processing operation.
        
        Args:
            name: Unique identifier for this instance. Used in logging
                and for identifying the processor in multi-instance setups.
                Must be non-empty and contain only alphanumeric characters
                and underscores.
            config: Configuration dictionary. Supported keys:
                - timeout (int): Processing timeout in seconds (default: 30)
                - retries (int): Number of retry attempts (default: 3)
                - verbose (bool): Enable verbose logging (default: False)
                Any additional keys are preserved for custom extensions.
            callback: Optional callback function called after each successful
                processing operation. Receives the processed data as argument.
                
        Raises:
            ValueError: If name is empty or contains invalid characters
            TypeError: If config is not a dictionary or callback is not callable
            
        Example:
            >>> def my_callback(data):
            ...     print(f"Processed: {data['id']}")
            >>> instance = WellDocumentedClass(
            ...     "processor_1",
            ...     config={"timeout": 60},
            ...     callback=my_callback
            ... )
        """
        # Validate inputs
        if not name or not name.replace('_', '').isalnum():
            raise ValueError(f"Invalid name: {name}")
            
        # Initialize instance attributes
        self.name: str = name
        self.config: Dict[str, Any] = {**self.DEFAULT_CONFIG, **(config or {})}
        self._callback: Optional[CallbackFunction] = callback
        self._active: bool = False
        self._processed_count: int = 0
        
        # Initialize logging for this instance
        self._logger = logging.getLogger(f"{__name__}.{name}")
        if self.config.get("verbose"):
            self._logger.setLevel(logging.DEBUG)
            
        self._logger.info(f"Initialized {self.__class__.__name__} '{name}'")
    
    @property
    def is_active(self) -> bool:
        """Check if the processor is currently active.
        
        Returns:
            True if the processor is active and processing data,
            False otherwise.
            
        Note:
            This is a read-only property. Use start() and stop()
            to change the active state.
        """
        return self._active
    
    @property
    def processed_count(self) -> int:
        """Get the total number of items processed.
        
        Returns:
            Count of successfully processed items since instantiation
            or last reset. Failed processing attempts are not counted.
        """
        return self._processed_count
    
    def start(self) -> None:
        """Start the processor.
        
        Initializes any required resources and sets the processor
        to active state. This method is idempotent - calling it
        multiple times has no effect if already started.
        
        Raises:
            RuntimeError: If required resources cannot be initialized
            
        Example:
            >>> instance = WellDocumentedClass("processor")
            >>> instance.start()
            >>> assert instance.is_active
        """
        if self._active:
            self._logger.debug("Already active, skipping start")
            return
            
        self._logger.info("Starting processor")
        
        # Initialize resources (placeholder for real implementation)
        self._initialize_resources()
        
        self._active = True
        self._logger.info("Processor started successfully")
    
    def stop(self) -> None:
        """Stop the processor and clean up resources.
        
        Gracefully shuts down the processor and releases any held
        resources. This method is idempotent and safe to call even
        if the processor is not active.
        
        Note:
            This method will wait up to config['timeout'] seconds
            for any in-progress operations to complete.
        """
        if not self._active:
            self._logger.debug("Not active, skipping stop")
            return
            
        self._logger.info("Stopping processor")
        
        # Cleanup resources (placeholder for real implementation)
        self._cleanup_resources()
        
        self._active = False
        self._logger.info("Processor stopped")
    
    def process_data(
        self,
        data: NotificationData,
        priority: str = "normal",
        dry_run: bool = False
    ) -> ProcessingResult:
        """Process a single data item.
        
        Processes the provided data according to its type and the current
        configuration. Supports different priority levels and dry-run mode
        for testing.
        
        Args:
            data: Dictionary containing the data to process. Required keys:
                - type (str): One of SUPPORTED_TYPES
                - id (str): Unique identifier
                - content (Any): The actual data to process
            priority: Processing priority. Options:
                - "high": Process immediately, skip queue
                - "normal": Standard processing (default)
                - "low": Process when resources available
            dry_run: If True, simulate processing without making changes.
                Useful for testing and validation.
                
        Returns:
            Tuple containing:
                - success (bool): Whether processing succeeded
                - error (Optional[str]): Error message if failed, None if success
                - metadata (Dict[str, Any]): Processing metadata including:
                    - duration_ms: Processing time in milliseconds
                    - retries: Number of retry attempts
                    - timestamp: Completion timestamp
                    
        Raises:
            ValueError: If data type is not supported or required keys missing
            RuntimeError: If processor is not active
            
        Example:
            >>> instance = WellDocumentedClass("proc")
            >>> instance.start()
            >>> success, error, meta = instance.process_data({
            ...     "type": "notification",
            ...     "id": "123",
            ...     "content": {"message": "Hello"}
            ... })
            >>> if success:
            ...     print(f"Processed in {meta['duration_ms']}ms")
            ... else:
            ...     print(f"Failed: {error}")
                    
        Performance:
            - Average processing time: 50-100ms
            - Memory usage: O(n) where n is size of content
            - Network calls: 0-2 depending on configuration
        """
        # Validate state
        if not self._active:
            raise RuntimeError("Processor is not active. Call start() first.")
            
        # Validate input data structure
        required_keys = {"type", "id", "content"}
        missing_keys = required_keys - set(data.keys())
        if missing_keys:
            raise ValueError(f"Missing required keys: {missing_keys}")
            
        # Validate data type is supported
        if data["type"] not in self.SUPPORTED_TYPES:
            raise ValueError(
                f"Unsupported type '{data['type']}'. "
                f"Supported types: {self.SUPPORTED_TYPES}"
            )
            
        # Start processing timer
        start_time = datetime.now()
        
        # Simulate processing with detailed logging
        self._logger.debug(
            f"Processing {data['type']} '{data['id']}' "
            f"with priority '{priority}'"
        )
        
        try:
            # Actual processing would go here
            # For now, we'll simulate it
            if dry_run:
                self._logger.info(f"Dry run: Would process {data['id']}")
                result = True
            else:
                result = self._perform_processing(data, priority)
                
            # Calculate processing duration
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            
            # Build metadata
            metadata = {
                "duration_ms": round(duration_ms, 2),
                "retries": 0,  # Would track actual retries
                "timestamp": datetime.now().isoformat(),
                "priority": priority,
                "dry_run": dry_run
            }
            
            if result:
                # Success case
                if not dry_run:
                    self._processed_count += 1
                    
                    # Call callback if provided
                    if self._callback:
                        try:
                            self._callback(data)
                        except Exception as e:
                            self._logger.error(
                                f"Callback error: {e}", exc_info=True
                            )
                            
                return (True, None, metadata)
            else:
                # Failure case
                error_msg = "Processing failed for unknown reason"
                return (False, error_msg, metadata)
                
        except Exception as e:
            # Handle any unexpected errors
            self._logger.error(
                f"Error processing {data['id']}: {e}", exc_info=True
            )
            
            duration_ms = (datetime.now() - start_time).total_seconds() * 1000
            metadata = {
                "duration_ms": round(duration_ms, 2),
                "retries": 0,
                "timestamp": datetime.now().isoformat(),
                "priority": priority,
                "dry_run": dry_run,
                "exception": str(e)
            }
            
            return (False, str(e), metadata)
    
    def batch_process(
        self,
        items: List[NotificationData],
        max_workers: int = 4,
        stop_on_error: bool = False
    ) -> Dict[str, Any]:
        """Process multiple items in batch.
        
        Efficiently processes multiple items with configurable parallelism.
        Provides detailed results and statistics for the batch operation.
        
        Args:
            items: List of data items to process. Each item must conform
                to the structure expected by process_data().
            max_workers: Maximum number of parallel workers. Set to 1 for
                sequential processing. Default: 4
            stop_on_error: If True, stop processing on first error.
                If False, continue processing remaining items. Default: False
                
        Returns:
            Dictionary containing batch results:
                - total: Total number of items
                - successful: Number of successfully processed items
                - failed: Number of failed items
                - errors: List of (item_id, error_message) tuples
                - duration_ms: Total batch processing time
                - items_per_second: Average processing rate
                
        Example:
            >>> items = [
            ...     {"type": "notification", "id": "1", "content": {}},
            ...     {"type": "alert", "id": "2", "content": {}}
            ... ]
            >>> results = instance.batch_process(items, max_workers=2)
            >>> print(f"Processed {results['successful']}/{results['total']}")
            
        Note:
            For large batches (>1000 items), consider using
            batch_process_chunked() instead to manage memory usage.
        """
        # Implementation would include parallel processing logic
        # This is a simplified version for documentation example
        
        start_time = datetime.now()
        results = {
            "total": len(items),
            "successful": 0,
            "failed": 0,
            "errors": [],
            "duration_ms": 0,
            "items_per_second": 0
        }
        
        self._logger.info(f"Starting batch processing of {len(items)} items")
        
        for item in items:
            try:
                success, error, _ = self.process_data(item)
                if success:
                    results["successful"] += 1
                else:
                    results["failed"] += 1
                    results["errors"].append((item.get("id", "unknown"), error))
                    
                    if stop_on_error:
                        self._logger.warning("Stopping batch due to error")
                        break
                        
            except Exception as e:
                results["failed"] += 1
                results["errors"].append((item.get("id", "unknown"), str(e)))
                
                if stop_on_error:
                    break
                    
        # Calculate final statistics
        duration_ms = (datetime.now() - start_time).total_seconds() * 1000
        results["duration_ms"] = round(duration_ms, 2)
        
        if duration_ms > 0:
            results["items_per_second"] = round(
                (results["successful"] / duration_ms) * 1000, 2
            )
            
        self._logger.info(
            f"Batch processing complete: "
            f"{results['successful']}/{results['total']} successful"
        )
        
        return results
    
    def _initialize_resources(self) -> None:
        """Initialize internal resources.
        
        Private method to set up any resources needed for processing.
        This is called by start() and should not be called directly.
        
        Raises:
            RuntimeError: If resources cannot be initialized
        """
        # Placeholder for resource initialization
        # In real implementation, might set up:
        # - Database connections
        # - Thread pools
        # - Cache structures
        # - Network connections
        self._logger.debug("Resources initialized")
    
    def _cleanup_resources(self) -> None:
        """Clean up internal resources.
        
        Private method to release resources. Called by stop() and
        should not be called directly. Implements graceful shutdown
        with timeout based on configuration.
        """
        # Placeholder for resource cleanup
        # In real implementation, might clean up:
        # - Close database connections
        # - Shutdown thread pools
        # - Flush caches
        # - Close network connections
        self._logger.debug("Resources cleaned up")
    
    def _perform_processing(
        self,
        data: NotificationData,
        priority: str
    ) -> bool:
        """Perform actual processing of data.
        
        Private method that implements the core processing logic.
        This is where the real work happens in a production system.
        
        Args:
            data: The data to process
            priority: Processing priority level
            
        Returns:
            True if processing succeeded, False otherwise
        """
        # Simulate processing
        # In real implementation, this would:
        # - Transform data
        # - Apply business logic
        # - Store results
        # - Update metrics
        
        # Simulate some work
        import time
        time.sleep(0.01)  # 10ms processing time
        
        return True  # Simulate success
    
    def __repr__(self) -> str:
        """Return string representation of instance.
        
        Returns:
            String in format: ClassName(name='...', active=True/False)
        """
        return (
            f"{self.__class__.__name__}("
            f"name='{self.name}', "
            f"active={self._active})"
        )
    
    def __str__(self) -> str:
        """Return human-readable string representation.
        
        Returns:
            String describing the instance state
        """
        return (
            f"{self.__class__.__name__} '{self.name}' "
            f"({'active' if self._active else 'inactive'}, "
            f"{self._processed_count} processed)"
        )


def example_usage() -> None:
    """Demonstrate proper usage of the documented class.
    
    This function shows various ways to use WellDocumentedClass
    with different configurations and error handling patterns.
    """
    # Configure logging to see output
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Example 1: Basic usage
    print("Example 1: Basic usage")
    processor = WellDocumentedClass("example_processor")
    processor.start()
    
    # Process a single item
    result = processor.process_data({
        "type": "notification",
        "id": "msg_001",
        "content": {"text": "Hello, World!"}
    })
    
    success, error, metadata = result
    if success:
        print(f"✓ Processed successfully in {metadata['duration_ms']}ms")
    else:
        print(f"✗ Processing failed: {error}")
        
    processor.stop()
    print()
    
    # Example 2: With configuration and callback
    print("Example 2: With configuration and callback")
    
    def notification_callback(data: NotificationData) -> None:
        """Callback function called after processing."""
        print(f"  Callback: Processed {data['id']}")
    
    processor2 = WellDocumentedClass(
        "configured_processor",
        config={"timeout": 60, "verbose": True},
        callback=notification_callback
    )
    
    processor2.start()
    
    # Process multiple items
    items = [
        {"type": "notification", "id": f"msg_{i:03d}", "content": {"index": i}}
        for i in range(5)
    ]
    
    results = processor2.batch_process(items, max_workers=2)
    print(f"  Batch results: {results['successful']}/{results['total']} successful")
    print(f"  Processing rate: {results['items_per_second']} items/second")
    
    processor2.stop()
    print()
    
    # Example 3: Error handling
    print("Example 3: Error handling")
    processor3 = WellDocumentedClass("error_handler")
    
    # Try to process without starting (should raise error)
    try:
        processor3.process_data({"type": "alert", "id": "001", "content": {}})
    except RuntimeError as e:
        print(f"  Expected error: {e}")
    
    # Start and try invalid data
    processor3.start()
    
    try:
        processor3.process_data({"type": "invalid_type", "id": "002", "content": {}})
    except ValueError as e:
        print(f"  Expected error: {e}")
    
    processor3.stop()
    print()
    
    # Example 4: Dry run mode
    print("Example 4: Dry run mode")
    processor4 = WellDocumentedClass("dry_run_test")
    processor4.start()
    
    # Test processing without making changes
    success, _, _ = processor4.process_data(
        {"type": "event", "id": "test_001", "content": {"test": True}},
        dry_run=True
    )
    
    print(f"  Dry run successful: {success}")
    print(f"  Items processed (should be 0): {processor4.processed_count}")
    
    processor4.stop()


if __name__ == "__main__":
    # Run the examples when module is executed directly
    example_usage()
